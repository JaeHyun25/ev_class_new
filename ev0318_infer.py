import numpy as np
import pandas as pd
import joblib
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix

# ğŸš€ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (ì‚¬ìš©ìê°€ ë°ì´í„° ë¡œë“œ í•„ìš”)
def load_data(df):
    X = df.drop(columns=["carname", "folder", "ev"])
    y = df["ev"]
    return X, y

# ğŸš€ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_model(df):
    X, y = load_data(df)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # XGBoost ì´ˆê¸° í•™ìŠµ ë° FN ë¶„ì„
    initial_xgb = XGBClassifier(random_state=42)
    initial_xgb.fit(X_train, y_train)
    initial_pred = initial_xgb.predict(X_test)
    fn_ratio = sum((y_test == 1) & (initial_pred == 0)) / len(X_train)
    scale_pos_weight = 1 / fn_ratio

    # ğŸš€ ìµœì í™”ëœ XGBoost ëª¨ë¸
    xgb_model = XGBClassifier(
        scale_pos_weight=scale_pos_weight,
        n_estimators=200,
        learning_rate=0.1,
        max_depth=6,
        random_state=42
    )
    xgb_model.fit(X_train, y_train)

    # ğŸš€ ìµœì í™”ëœ LightGBM ëª¨ë¸
    lgbm_model = LGBMClassifier(
        n_estimators=200,
        learning_rate=0.11,
        num_leaves=30,
        random_state=42
    )
    lgbm_model.fit(X_train, y_train)

    # ëª¨ë¸ ì €ì¥
    joblib.dump(xgb_model, "xgb_model.pkl")
    joblib.dump(lgbm_model, "lgbm_model.pkl")
    print("âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: xgb_model.pkl, lgbm_model.pkl")

    return xgb_model, lgbm_model, X_test, y_test

# ğŸš€ Inference í•¨ìˆ˜
def inference(new_data):
    xgb_model = joblib.load("xgb_model.pkl")
    lgbm_model = joblib.load("lgbm_model.pkl")
    
    y_prob_xgb = xgb_model.predict_proba(new_data)[:, 1]
    best_threshold = 0.45
    low_confidence_cases = y_prob_xgb < best_threshold
    
    y_pred_final = xgb_model.predict(new_data)
    y_pred_final[low_confidence_cases] = lgbm_model.predict(new_data[low_confidence_cases])
    
    return y_pred_final

# ğŸš€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‚¬ìš©ì ë°ì´í„° í•„ìš”)
if __name__ == "__main__":
    # ì‚¬ìš©ì ë°ì´í„° ë¡œë“œ í•„ìš” (dfë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œí•˜ë„ë¡ ìˆ˜ì • ê°€ëŠ¥)
    df = pd.read_csv("data.csv")  # ì‚¬ìš©ìì˜ ë°ì´í„° íŒŒì¼ë¡œ ë³€ê²½
    xgb_model, lgbm_model, X_test, y_test = train_model(df)
    
    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    y_pred_final = inference(X_test)
    print("\nğŸš€ ìµœì  ëª¨ë¸ ì„±ëŠ¥:")
    print(classification_report(y_test, y_pred_final))
    print("\ní˜¼ë™ í–‰ë ¬:")
    print(confusion_matrix(y_test, y_pred_final))
    print(f"\nPrecision: {precision_score(y_test, y_pred_final):.6f}")
    print(f"Recall: {recall_score(y_test, y_pred_final):.6f}")
    print(f"Accuracy: {accuracy_score(y_test, y_pred_final):.6f}")